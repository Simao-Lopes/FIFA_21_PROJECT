{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d09590d",
   "metadata": {},
   "source": [
    "# Fifa 21 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf6408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cfbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore python warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv('fifa21_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beda8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (d1, d2):   \n",
    "    #     # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "    #     # the model working and the scores calculated above\n",
    "    print('  R2 SCORE: Train', round(r2_score(d1, d2),3))\n",
    "    print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(d1, d2)),3))\n",
    "    print('Prediction Values')\n",
    "    display(d2[:5])\n",
    "    print('Real Values')\n",
    "    display(d1[:5])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123ef1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2dafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert K and M to normal numbering\n",
    "def value_to_float(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return x\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('K', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character replacing function\n",
    "def remove_char(x,y, z=''):\n",
    "    return x.apply(lambda d: d.replace(y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the columns and sum the values\n",
    "def split_columns(data):\n",
    "    return pd.to_numeric(data.str.split('+',n=1,expand=True)[0]) + pd.to_numeric(data.str.split('+',n=1,expand=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to apply python snake column names\n",
    "def std_data(x, y='_'):\n",
    "    x.columns = [e.lower().replace(' ','_') for e in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b86a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = working dataset, drp = columns to drop\n",
    "def fill_na(data, drp):\n",
    "    \n",
    "    # Dropping unwanted columns\n",
    "    data = data.drop(columns=drp, axis=1)\n",
    "    data = data[data['composure'].isna() == False]\n",
    "    \n",
    "    \n",
    "    # Fill Nan's with values\n",
    "#     data['position'].fillna(value=data['bp'], inplace=True)\n",
    "#     data['club'].fillna(value='None', inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b15185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that encodes categoricals either with one hot encoder, or a mix of one hot encoder + label encoder\n",
    "def cat_encode(data, exclude='', type_d=True):\n",
    "\n",
    "    if type_d:\n",
    "        tmp = data.drop(columns=exclude, axis=1)\n",
    "        encoder = OneHotEncoder(drop='first').fit(tmp)\n",
    "    else:\n",
    "        encoder = global_encoder\n",
    "\n",
    "    # Categorical encoder Label + onehot\n",
    "    # If no fields to label encode are provided only the one hot encoder is executed\n",
    "    if exclude == '':\n",
    "        \n",
    "        encoded = encoder.transform(data).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=data.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return onehot_encoded\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Label Encoder\n",
    "        le = LabelEncoder()\n",
    "        label_encoded = data[exclude]\n",
    "        label_encoded[exclude] = label_encoded[exclude].apply(le.fit_transform)\n",
    "        \n",
    "        # One hot encoder\n",
    "        tmp = data.drop(columns=exclude, axis=1)\n",
    "        encoded = encoder.transform(tmp).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=tmp.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return pd.concat([onehot_encoded, label_encoded], axis=1), encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_correlations(data)\n",
    "    # Ploting the correlations in numerical dataset\n",
    "    correlations_matrix = data.corr()\n",
    "    sns.set(rc = {'figure.figsize':(40,40)})\n",
    "    sns.heatmap(correlations_matrix)\n",
    "    plt.show()\n",
    "    display(correlations_matrix)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9495c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that builds the linear regression model\n",
    "def build_model(data, target):\n",
    "\n",
    "    # X-y Split\n",
    "    y = data[target]\n",
    "    X = data.drop([target], axis=1)\n",
    "    \n",
    "    # Getting numerical and categorical data separated\n",
    "    X_num = data.select_dtypes(np.number)\n",
    "    X_cat = data.select_dtypes('object')\n",
    "\n",
    "    X_cat, g_encoder = cat_encode(categorical, ['a/w', 'd/w'])\n",
    "\n",
    "    transformer = MinMaxScaler().fit(X)\n",
    "    X_normalized = transformer.transform(X)\n",
    "    X_normalized = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "        \n",
    "    #train test Splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Creating the linear regression object and training it\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "\n",
    "    # Making predictions with the taining and tes sub datasets to use in the evaluation section bellow\n",
    "    predictions = lm.predict(X_train)\n",
    "    predictions_test = lm.predict(X_test)\n",
    "\n",
    "    # Results Validation using the previously computed calculations\n",
    "    print('\\n\\nLinear Regression Performance Results\\n')\n",
    "    print('  R2 SCORE: Train', round(r2_score(y_train, predictions),3), ' | Test', round(r2_score(y_test, predictions_test), 3))\n",
    "    print(' MSE SCORE: Train', round(mean_squared_error(y_train,predictions),3), ' | Test', round(mean_squared_error(y_test,predictions_test), 3))\n",
    "    print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(y_train,predictions)),3), '| Test', round(np.sqrt(mean_squared_error(y_test,predictions_test)),3))\n",
    "    print(' MAE SCORE: Train', round(mean_absolute_error(y_train, predictions),3), '| Test', round(mean_absolute_error(y_test, predictions_test), 3))\n",
    "\n",
    "    # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "    # the model working and the scores calculated above\n",
    "    print('\\n\\nTraining Values')\n",
    "    display(y_train[:5])\n",
    "    print('Prediction Values')\n",
    "    display(predictions[:5])\n",
    "    \n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18085c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does numerous dataset manipulation operations, all described individually\n",
    "def data_crunch(data, columns_to_drop, currency_values, to_drop, plus_items, type_d=True):\n",
    "\n",
    "    # Replacing all the column values that have currency type like €numberK/M to simple numbers\n",
    "    for e in currency_values:\n",
    "        data[e] = remove_char(data[e],'€')                # Removing the € character\n",
    "        data[e] = data[e].apply(value_to_float)           # Converting the numbers to simple numbers\n",
    "\n",
    "    # Converting the numbers of column 'hits' to simple numbers\n",
    "    data['hits'] = data['hits'].apply(value_to_float)     \n",
    "    \n",
    "    # Converting weight_kg column from pounds to kg\n",
    "    data['weight_kg'] = remove_char(data['weight_kg'],'lbs')\n",
    "    data['weight_kg'] = data['weight_kg'].astype(float)*0.4532\n",
    "    # Converting height_cm column from in to cm\n",
    "    data['height_cm'] = remove_char(data['height_cm'],'\"')\n",
    "    data['height_cm'] = ((data.height_cm.str.split(\"'\").str[0].astype(int) * 12) + (data.height_cm.str.split(\"'\").str[1].astype(int)))*2.54\n",
    "    \n",
    "    # Removing ★ character from columns and converting to numerical type\n",
    "    for e in to_drop:\n",
    "        data[e] = remove_char(data[e],'★')\n",
    "        data[e] = data[e].astype(int)\n",
    "        \n",
    "    # Summing the values in the columns that have structure like n1+n2\n",
    "    for e in plus_items:\n",
    "        #calling split function to make the sum\n",
    "        data[e] = split_columns(data[e])\n",
    "    \n",
    "    # Concat the numerical and categorical sets to be fitted to linear regression and return the dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd490dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our main function wich defines activelly all the manipulation to do on the dataset\n",
    "# It has many variables that change everything in the operation, making it essy to change and see results almost imediatly\n",
    "# without having to change any code at all.\n",
    "# This function only needs the dataset as argument, and retuns the linear regression as intended.\n",
    "def prep_data(data, type_d=True):\n",
    "    \n",
    "    # PARAMETERS TO AJUST THE DATASET /BEGIN\n",
    "    # Variables to change parameters of cleaning\n",
    "    columns_to_drop = ['loan_date_end', 'id', 'name','club','position', 'team_&_contract', 'growth', 'joined', 'contract',\n",
    "                       'crossing','finishing','heading_accuracy','short_passing','volleys','dribbling','curve','fk_accuracy','long_passing',\n",
    "                       'ball_control','acceleration','sprint_speed','agility','reactions','balance','shot_power','jumping','stamina','strength','long_shots',\n",
    "                       'aggression','interceptions','positioning','vision','penalties','marking','standing_tackle','sliding_tackle',\n",
    "                       'gk_diving','gk_handling','gk_kicking','gk_positioning','gk_reflexes','total_stats','pac','sho','pas','dri','def','phy',\n",
    "                       'lwb','ldm','rdm','rwb','lb','lcb','rcb','rb', 'ls','rs','lf','rf','rw','cam','lm','nationality',\n",
    "                       'st','lw','cf','lam','ram','lcm','cm','rcm', 'attacking', 'skill', 'cdm', 'value_euro'] # My sugestions only\n",
    "    currency_values = ['wage_euro', 'release_clause_euro']\n",
    "    # Special coluns to remove ★ character\n",
    "    to_drop = ['w/f', 'sm', 'ir']\n",
    "    # Columns to split by '+' and sum the two halves\n",
    "    plus_items = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "    # Target for the linear regression module\n",
    "    target = 'ova'\n",
    "    # PARAMETERS TO AJUST THE DATASET /END\n",
    "\n",
    "    cleandata = std_data(data)\n",
    "    cleandata.rename(columns = {'height':'height_cm', 'weight':'weight_kg', 'value':'value_euro', 'wage':'wage_euro', 'release_clause':'release_clause_euro'}, inplace = True)\n",
    "    cleandata = fill_na(cleandata, columns_to_drop)\n",
    "    \n",
    "    results, g_encoder = data_crunch(cleandata, columns_to_drop, currency_values, to_drop, plus_items, type_d)\n",
    "    \n",
    "    return results, g_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddec0fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the model\n",
    "data, global_encoder = prep_data(dataset)\n",
    "lm = build_model(data, 'ova')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e42899",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944b628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_v = pd.read_csv('fifa21_validate.csv')\n",
    "data_v = prep_data(dataset_v, False)\n",
    "\n",
    "display(data_v)\n",
    "\n",
    "# _set = data_v.drop(['ova'], axis=1)\n",
    "# Making predictions with the new dataset\n",
    "predictions = lm.predict(data_v.drop(['ova'], axis=1))\n",
    "\n",
    "evaluate(dataset_v['ova'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git add .\n",
    "# !git status\n",
    "# !git commit -m \"Fifa 2021 Final \"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
