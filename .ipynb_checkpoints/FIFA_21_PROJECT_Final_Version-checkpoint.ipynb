{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d09590d",
   "metadata": {},
   "source": [
    "# Fifa 21 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddec0fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['positionteam_&_contract'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 224>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, g_encoder\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Using the model\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m data, global_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mprep_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m lm \u001b[38;5;241m=\u001b[39m build_model(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mova\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mprep_data\u001b[1;34m(data, type_d)\u001b[0m\n\u001b[0;32m    215\u001b[0m cleandata \u001b[38;5;241m=\u001b[39m std_data(data)\n\u001b[0;32m    216\u001b[0m cleandata\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight_cm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_kg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_euro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwage\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwage_euro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_clause\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_clause_euro\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 217\u001b[0m cleandata \u001b[38;5;241m=\u001b[39m \u001b[43mfill_na\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleandata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m results, g_encoder \u001b[38;5;241m=\u001b[39m data_crunch(cleandata, columns_to_drop, currency_values, to_drop, plus_items, type_d)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, g_encoder\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mfill_na\u001b[1;34m(data, drp)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_na\u001b[39m(data, drp):\n\u001b[0;32m     56\u001b[0m     \n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Dropping unwanted columns\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomposure\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Fill Nan's with values\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#     data['position'].fillna(value=data['bp'], inplace=True)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#     data['club'].fillna(value='None', inplace=True)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['positionteam_&_contract'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "\n",
    "#ignore python warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv('fifa21_train.csv')\n",
    "\n",
    "# Function to convert K and M to normal numbering\n",
    "def value_to_float(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return x\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('K', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    return float(x)\n",
    "\n",
    "# Character replacing function\n",
    "def remove_char(x,y, z=''):\n",
    "    return x.apply(lambda d: d.replace(y, z))\n",
    "\n",
    "# function to split the columns and sum the values\n",
    "def split_columns(data):\n",
    "    return pd.to_numeric(data.str.split('+',n=1,expand=True)[0]) + pd.to_numeric(data.str.split('+',n=1,expand=True)[1])\n",
    "\n",
    "# Functions to apply python snake column names\n",
    "def std_data(x, y='_'):\n",
    "    x.columns = [e.lower().replace(' ','_') for e in x]\n",
    "    return x\n",
    "\n",
    "# Data = working dataset, drp = columns to drop\n",
    "def fill_na(data, drp):\n",
    "    \n",
    "    # Dropping unwanted columns\n",
    "    data = data.drop(columns=drp, axis=1)\n",
    "    data = data[data['composure'].isna() == False]\n",
    "    \n",
    "    # Fill Nan's with values\n",
    "#     data['position'].fillna(value=data['bp'], inplace=True)\n",
    "#     data['club'].fillna(value='None', inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function that encodes categoricals either with one hot encoder, or a mix of one hot encoder + label encoder\n",
    "def cat_encode(data, exclude='', type_d=True):\n",
    "\n",
    "    if type_d:\n",
    "        tmp = data.drop(columns=exclude, axis=1)\n",
    "        encoder = OneHotEncoder(drop='first').fit(tmp)\n",
    "    else:\n",
    "        encoder = global_encoder\n",
    "\n",
    "    # Categorical encoder Label + onehot\n",
    "    # If no fields to label encode are provided only the one hot encoder is executed\n",
    "    if exclude == '':\n",
    "        \n",
    "        encoded = encoder.transform(data).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=data.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return onehot_encoded\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Label Encoder\n",
    "        le = LabelEncoder()\n",
    "        label_encoded = data[exclude]\n",
    "        label_encoded[exclude] = label_encoded[exclude].apply(le.fit_transform)\n",
    "        \n",
    "        # One hot encoder\n",
    "        tmp = data.drop(columns=exclude, axis=1)\n",
    "        encoded = encoder.transform(tmp).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=tmp.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return pd.concat([onehot_encoded, label_encoded], axis=1), encoder\n",
    "    \n",
    "# Function that builds the linear regression model\n",
    "def build_model(data, target):\n",
    "\n",
    "    # X-y Split\n",
    "    y = data[target]\n",
    "    X = data.drop([target], axis=1)\n",
    "    \n",
    "    transformer = MinMaxScaler().fit(X)\n",
    "    X_normalized = transformer.transform(X)\n",
    "    X_normalized = pd.DataFrame(X_normalized, columns=X.columns)\n",
    " \n",
    "    display(X.head())\n",
    "        \n",
    "    #train test Splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "    # Creating the linear regression object and training it\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "\n",
    "    # Making predictions with the taining and tes sub datasets to use in the evaluation section bellow\n",
    "    predictions = lm.predict(X_train)\n",
    "    predictions_test = lm.predict(X_test)\n",
    "\n",
    "    # Results Validation using the previously computed calculations\n",
    "    print('\\n\\nLinear Regression Performance Results\\n')\n",
    "    print('  R2 SCORE: Train', round(r2_score(y_train, predictions),3), ' | Test', round(r2_score(y_test, predictions_test), 3))\n",
    "    print(' MSE SCORE: Train', round(mean_squared_error(y_train,predictions),3), ' | Test', round(mean_squared_error(y_test,predictions_test), 3))\n",
    "    print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(y_train,predictions)),3), '| Test', round(np.sqrt(mean_squared_error(y_test,predictions_test)),3))\n",
    "    print(' MAE SCORE: Train', round(mean_absolute_error(y_train, predictions),3), '| Test', round(mean_absolute_error(y_test, predictions_test), 3))\n",
    "\n",
    "    # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "    # the model working and the scores calculated above\n",
    "    print('\\n\\nTraining Values')\n",
    "    display(y_train[:5])\n",
    "    print('Prediction Values')\n",
    "    display(predictions[:5])\n",
    "    \n",
    "    return lm\n",
    "\n",
    "# Function that does numerous dataset manipulation operations, all described individually\n",
    "def data_crunch(data, columns_to_drop, currency_values, to_drop, plus_items, type_d=True):\n",
    "\n",
    "    # Replacing all the column values that have currency type like €numberK/M to simple numbers\n",
    "    for e in currency_values:\n",
    "        data[e] = remove_char(data[e],'€')                # Removing the € character\n",
    "        data[e] = data[e].apply(value_to_float)           # Converting the numbers to simple numbers\n",
    "\n",
    "    # Converting the numbers of column 'hits' to simple numbers\n",
    "    data['hits'] = data['hits'].apply(value_to_float)     \n",
    "    \n",
    "    # Converting weight_kg column from pounds to kg\n",
    "    data['weight_kg'] = remove_char(data['weight_kg'],'lbs')\n",
    "    data['weight_kg'] = data['weight_kg'].astype(float)*0.4532\n",
    "    # Converting height_cm column from in to cm\n",
    "    data['height_cm'] = remove_char(data['height_cm'],'\"')\n",
    "    data['height_cm'] = ((data.height_cm.str.split(\"'\").str[0].astype(int) * 12) + (data.height_cm.str.split(\"'\").str[1].astype(int)))*2.54\n",
    "    \n",
    "    # Removing ★ character from columns and converting to numerical type\n",
    "    for e in to_drop:\n",
    "        data[e] = remove_char(data[e],'★')\n",
    "        data[e] = data[e].astype(int)\n",
    "        \n",
    "    # Summing the values in the columns that have structure like n1+n2\n",
    "    for e in plus_items:\n",
    "        for i in data.columns:\n",
    "            #test if values of i and e are equal\n",
    "            if i == e:\n",
    "                #calling split function to make the sum\n",
    "                data[e] = split_columns(data[e])\n",
    "                \n",
    "    # Getting numerical and categorical data separated\n",
    "    numerical = data.select_dtypes(np.number)\n",
    "    categorical = data.select_dtypes('object')\n",
    "\n",
    "    # Encoding the categorical data, a/w and d/w will be label encoded and the remaining will be one hot encoded\n",
    "    categorical, g_encoder = cat_encode(categorical, ['a/w', 'd/w'],type_d)\n",
    "    \n",
    "    # Ploting the correlations in numerical dataset\n",
    "    correlations_matrix = numerical.corr()\n",
    "    sns.set(rc = {'figure.figsize':(40,40)})\n",
    "    sns.heatmap(correlations_matrix)\n",
    "    plt.show()\n",
    "    display(correlations_matrix)\n",
    "    \n",
    "    # Concat the numerical and categorical sets to be fitted to linear regression and return the dataset\n",
    "    return pd.concat([numerical, categorical], axis=1), g_encoder\n",
    "    \n",
    "\n",
    "# This is our main function wich defines activelly all the manipulation to do on the dataset\n",
    "# It has many variables that change everything in the operation, making it essy to change and see results almost imediatly\n",
    "# without having to change any code at all.\n",
    "# This function only needs the dataset as argument, and retuns the linear regression as intended.\n",
    "def prep_data(data, type_d=True):\n",
    "    \n",
    "    # PARAMETERS TO AJUST THE DATASET /BEGIN\n",
    "    # Variables to change parameters of cleaning\n",
    "    columns_to_drop = ['loan_date_end', 'id', 'name','club','position' 'team_&_contract', 'growth', 'joined', 'contract',\n",
    "                       'crossing','finishing','heading_accuracy','short_passing','volleys','dribbling','curve','fk_accuracy','long_passing',\n",
    "                       'ball_control','acceleration','sprint_speed','agility','reactions','balance','shot_power','jumping','stamina','strength','long_shots',\n",
    "                       'aggression','interceptions','positioning','vision','penalties','marking','standing_tackle','sliding_tackle',\n",
    "                       'gk_diving','gk_handling','gk_kicking','gk_positioning','gk_reflexes','total_stats','pac','sho','pas','dri','def','phy',\n",
    "                       'lwb','ldm','rdm','rwb','lb','lcb','rcb','rb', 'ls','rs','lf','rf','rw','cam','lm','nationality',\n",
    "                       'st','lw','cf','lam','ram','lcm','cm','rcm', 'attacking', 'skill', 'cdm', 'value_euro'] # My sugestions only\n",
    "    currency_values = ['wage_euro', 'release_clause_euro']\n",
    "    # Special coluns to remove ★ character\n",
    "    to_drop = ['w/f', 'sm', 'ir']\n",
    "    # Columns to split by '+' and sum the two halves\n",
    "    plus_items = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "    # Target for the linear regression module\n",
    "    target = 'ova'\n",
    "    # PARAMETERS TO AJUST THE DATASET /END\n",
    "\n",
    "    cleandata = std_data(data)\n",
    "    cleandata.rename(columns = {'height':'height_cm', 'weight':'weight_kg', 'value':'value_euro', 'wage':'wage_euro', 'release_clause':'release_clause_euro'}, inplace = True)\n",
    "    cleandata = fill_na(cleandata, columns_to_drop)\n",
    "    \n",
    "    results, g_encoder = data_crunch(cleandata, columns_to_drop, currency_values, to_drop, plus_items, type_d)\n",
    "    \n",
    "    return results, g_encoder\n",
    "\n",
    "# Using the model\n",
    "data, global_encoder = prep_data(dataset)\n",
    "lm = build_model(data, 'ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (d1, d2):   \n",
    "    #     # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "    #     # the model working and the scores calculated above\n",
    "    print('  R2 SCORE: Train', round(r2_score(d1, d2),3))\n",
    "    print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(d1, d2)),3))\n",
    "    print('Prediction Values')\n",
    "    display(d2[:5])\n",
    "    print('Real Values')\n",
    "    display(d1[:5])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944b628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_v = pd.read_csv('fifa21_validate.csv')\n",
    "data_v = prep_data(dataset_v, False)\n",
    "\n",
    "# _set = data_v.drop(['ova'], axis=1)\n",
    " # Making predictions with the new dataset\n",
    "predictions = lm.predict(data_v)\n",
    "\n",
    "evaluate(dataset_v['ova'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git add .\n",
    "# !git status\n",
    "# !git commit -m \"Fifa 2021 Final \"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
