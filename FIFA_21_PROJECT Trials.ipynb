{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d09590d",
   "metadata": {},
   "source": [
    "# Fifa 21 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddec0fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 224>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_model(data_crunch(cleandata, columns_to_drop, currency_values, to_drop, plus_items), target)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# Using the model\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mlinear_regression\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    218\u001b[0m cleandata\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight_cm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_kg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_euro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwage\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwage_euro\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_clause\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_clause_euro\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    219\u001b[0m cleandata \u001b[38;5;241m=\u001b[39m fill_na(cleandata, columns_to_drop)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m build_model(\u001b[43mdata_crunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleandata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrency_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplus_items\u001b[49m\u001b[43m)\u001b[49m, target)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mdata_crunch\u001b[1;34m(data, columns_to_drop, currency_values, to_drop, plus_items)\u001b[0m\n\u001b[0;32m    175\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_normalized, columns\u001b[38;5;241m=\u001b[39mX_num\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    176\u001b[0m X_num \u001b[38;5;241m=\u001b[39m numerical\u001b[38;5;241m.\u001b[39mselect_dtypes(include \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnumber)\n\u001b[1;32m--> 178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx_num\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Encoding the categorical data, a/w and d/w will be label encoded and the remaining will be one hot encoded\u001b[39;00m\n\u001b[0;32m    180\u001b[0m categorical \u001b[38;5;241m=\u001b[39m cat_encode(categorical, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma/w\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md/w\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_num' is not defined"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "\n",
    "#ignore python warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv('fifa21_train.csv')\n",
    "\n",
    "# Function to convert K and M to normal numbering\n",
    "def value_to_float(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return x\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('K', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    return float(x)\n",
    "\n",
    "# Character replacing function\n",
    "def remove_char(x,y, z=''):\n",
    "    return x.apply(lambda d: d.replace(y, z))\n",
    "\n",
    "# function to split the columns and sum the values\n",
    "def split_columns(data):\n",
    "    return pd.to_numeric(data.str.split('+',n=1,expand=True)[0]) + pd.to_numeric(data.str.split('+',n=1,expand=True)[1])\n",
    "\n",
    "# Functions to apply python snake column names\n",
    "def std_data(x, y='_'):\n",
    "    x.columns = [e.lower().replace(' ','_') for e in x]\n",
    "    return x\n",
    "\n",
    "# Data = working dataset, drp = columns to drop\n",
    "def fill_na(data, drp):\n",
    "    \n",
    "    # Dropping unwanted columns\n",
    "    data = data.drop(columns=drp, axis=1)\n",
    "    data = data[data['composure'].isna() == False]\n",
    "    \n",
    "    # Fill Nan's with values\n",
    "    data['position'].fillna(value=data['bp'], inplace=True)\n",
    "    data['club'].fillna(value='None', inplace=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function that encodes categoricals either with one hot encoder, or a mix of one hot encoder + label encoder\n",
    "def cat_encode(data, exclude=''):\n",
    "\n",
    "\n",
    "    # Categorical encoder Label + onehot\n",
    "    # If no fields to label encode are provided only the one hot encoder is executed\n",
    "    if exclude == '':\n",
    "        \n",
    "        encoder = OneHotEncoder(drop='first').fit(data)\n",
    "        encoded = encoder.transform(data).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=data.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return onehot_encoded\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Label Encoder\n",
    "        le = LabelEncoder()\n",
    "        label_encoded = data[exclude]\n",
    "        label_encoded[exclude] = label_encoded[exclude].apply(le.fit_transform)\n",
    "        \n",
    "        # One hot encoder\n",
    "        tmp = data.drop(columns=exclude, axis=1)\n",
    "        encoder = OneHotEncoder(drop='first').fit(tmp)\n",
    "        encoded = encoder.transform(tmp).toarray()\n",
    "        cols = encoder.get_feature_names(input_features=tmp.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "        \n",
    "        return pd.concat([onehot_encoded, label_encoded], axis=1)\n",
    "    \n",
    "# Function that builds the linear regression model\n",
    "def build_model(data, target):\n",
    "\n",
    "    # X-y Split\n",
    "    y = data[target]\n",
    "    X = data.drop([target], axis=1)\n",
    "    \n",
    "    display(y.head())\n",
    "    display(X.head())\n",
    "        \n",
    "    #train test Splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "    # Creating the linear regression object and training it\n",
    "    lm = linear_model.LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "\n",
    "    # Making predictions with the taining and tes sub datasets to use in the evaluation section bellow\n",
    "    predictions = lm.predict(X_train)\n",
    "    predictions_test = lm.predict(X_test)\n",
    "\n",
    "    # Results Validation using the previously computed calculations\n",
    "    print('\\n\\nLinear Regression Performance Results\\n')\n",
    "    print('  R2 SCORE: Train', round(r2_score(y_train, predictions),3), ' | Test', round(r2_score(y_test, predictions_test), 3))\n",
    "    print(' MSE SCORE: Train', round(mean_squared_error(y_train,predictions),3), ' | Test', round(mean_squared_error(y_test,predictions_test), 3))\n",
    "    print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(y_train,predictions)),3), '| Test', round(np.sqrt(mean_squared_error(y_test,predictions_test)),3))\n",
    "    print(' MAE SCORE: Train', round(mean_absolute_error(y_train, predictions),3), '| Test', round(mean_absolute_error(y_test, predictions_test), 3))\n",
    "\n",
    "    # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "    # the model working and the scores calculated above\n",
    "    print('\\n\\nTraining Values')\n",
    "    display(y_train[:5])\n",
    "    print('Prediction Values')\n",
    "    display(predictions[:5])\n",
    "    \n",
    "    return lm\n",
    "\n",
    "# Function that does numerous dataset manipulation operations, all described individually\n",
    "def data_crunch(data, columns_to_drop, currency_values, to_drop, plus_items):\n",
    "\n",
    "    # Replacing all the column values that have currency type like €numberK/M to simple numbers\n",
    "    for e in currency_values:\n",
    "        data[e] = remove_char(data[e],'€')                # Removing the € character\n",
    "        data[e] = data[e].apply(value_to_float)           # Converting the numbers to simple numbers\n",
    "\n",
    "    # Converting the numbers of column 'hits' to simple numbers\n",
    "    data['hits'] = data['hits'].apply(value_to_float)     \n",
    "    \n",
    "    # Converting weight_kg column from pounds to kg\n",
    "    data['weight_kg'] = remove_char(data['weight_kg'],'lbs')\n",
    "    data['weight_kg'] = data['weight_kg'].astype(float)*0.4532\n",
    "    # Converting height_cm column from in to cm\n",
    "    data['height_cm'] = remove_char(data['height_cm'],'\"')\n",
    "    data['height_cm'] = ((data.height_cm.str.split(\"'\").str[0].astype(int) * 12) + (data.height_cm.str.split(\"'\").str[1].astype(int)))*2.54\n",
    "    \n",
    "    # Removing ★ character from columns and converting to numerical type\n",
    "    for e in to_drop:\n",
    "        data[e] = remove_char(data[e],'★')\n",
    "        data[e] = data[e].astype(int)\n",
    "        \n",
    "    # Summing the values in the columns that have structure like n1+n2\n",
    "    for e in plus_items:\n",
    "        for i in data.columns:\n",
    "            #test if values of i and e are equal\n",
    "            if i == e:\n",
    "                #calling split function to make the sum\n",
    "                data[e] = split_columns(data[e])\n",
    "                \n",
    "    # Getting numerical and categorical data separated\n",
    "    numerical = data.select_dtypes(np.number)\n",
    "    categorical = data.select_dtypes('object')\n",
    "    \n",
    "    X_num = numerical.drop(['ova'], axis=1)\n",
    "\n",
    "    transformer = MinMaxScaler().fit(X_num)\n",
    "    X_normalized = transformer.transform(X_num)\n",
    "    X_normalized = pd.DataFrame(X_normalized, columns=X_num.columns)\n",
    "    X_num = numerical.select_dtypes(include = np.number)\n",
    "\n",
    "    print(x_num.head())\n",
    "    # Encoding the categorical data, a/w and d/w will be label encoded and the remaining will be one hot encoded\n",
    "    categorical = cat_encode(categorical, ['a/w', 'd/w'])\n",
    "    \n",
    "    # Ploting the correlations in numerical dataset\n",
    "    correlations_matrix = numerical.corr()\n",
    "    sns.set(rc = {'figure.figsize':(40,40)})\n",
    "    sns.heatmap(correlations_matrix)\n",
    "    plt.show()\n",
    "    display(correlations_matrix)\n",
    "    \n",
    "    # Concat the numerical and categorical sets to be fitted to linear regression and return the dataset\n",
    "    return pd.concat([X_num, categorical], axis=1)\n",
    "    \n",
    "\n",
    "# This is our main function wich defines activelly all the manipulation to do on the dataset\n",
    "# It has many variables that change everything in the operation, making it essy to change and see results almost imediatly\n",
    "# without having to change any code at all.\n",
    "# This function only needs the dataset as argument, and retuns the linear regression as intended.\n",
    "def linear_regression(data):\n",
    "    \n",
    "    # PARAMETERS TO AJUST THE DATASET /BEGIN\n",
    "    # Variables to change parameters of cleaning\n",
    "    columns_to_drop = ['loan_date_end', 'id', 'name', 'team_&_contract', 'growth', 'joined', 'contract',\n",
    "                       'crossing','finishing','heading_accuracy','short_passing','volleys','dribbling','curve','fk_accuracy','long_passing',\n",
    "                       'ball_control','acceleration','sprint_speed','agility','reactions','balance','shot_power','jumping','stamina','strength','long_shots',\n",
    "                       'aggression','interceptions','positioning','vision','penalties','marking','standing_tackle','sliding_tackle',\n",
    "                       'gk_diving','gk_handling','gk_kicking','gk_positioning','gk_reflexes','total_stats','pac','sho','pas','dri','def','phy',\n",
    "                       'lwb','ldm','rdm','rwb','lb','lcb','rcb','rb', 'ls','rs','lf','rf','rw','cam','lm','nationality',\n",
    "                       'st','lw','cf','lam','ram','lcm','cm','rcm', 'attacking', 'skill', 'cdm', 'value_euro'] # My sugestions only\n",
    "    currency_values = ['wage_euro', 'release_clause_euro']\n",
    "    # Special coluns to remove ★ character\n",
    "    to_drop = ['w/f', 'sm', 'ir']\n",
    "    # Columns to split by '+' and sum the two halves\n",
    "    plus_items = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "    # Target for the linear regression module\n",
    "    target = 'ova'\n",
    "    # PARAMETERS TO AJUST THE DATASET /END\n",
    "\n",
    "    cleandata = std_data(data)\n",
    "    cleandata.rename(columns = {'height':'height_cm', 'weight':'weight_kg', 'value':'value_euro', 'wage':'wage_euro', 'release_clause':'release_clause_euro'}, inplace = True)\n",
    "    cleandata = fill_na(cleandata, columns_to_drop)\n",
    "    \n",
    "    return build_model(data_crunch(cleandata, columns_to_drop, currency_values, to_drop, plus_items), target)\n",
    "\n",
    "# Using the model\n",
    "lm = linear_regression(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd85e27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Simple function to use the linear regression\n",
    "# def predict(l_regression, _set):\n",
    "    \n",
    "#     # Making predictions with the taining and tes sub datasets to use in the evaluation section bellow\n",
    "#     predictions = l_regression(_set)\n",
    "\n",
    "#     # Printing just 5 results that we know from the Label set(y_train) and 5 predictions to check visualy  \n",
    "#     # the model working and the scores calculated above\n",
    "#     print('  R2 SCORE: Train', round(r2_score(y_train, predictions),3))\n",
    "#     print('RMSE SCORE: Train', round(np.sqrt(mean_squared_error(y_train,predictions)),3))\n",
    "#     print('Prediction Values')\n",
    "#     display(predictions[:5])\n",
    "    \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65933353",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git status\n",
    "!git commit -m \"Fifa 2021 Delivery version\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6990fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
